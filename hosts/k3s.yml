# configure Kubernetes cluster using k3s
- name: configure K3S Cluster Nodes
  hosts:
    - k3s
  roles: 
    - VM_role
    - git_config_role
    - git_dotfiles_role
    - linux_role
    - drake_role
  tasks:

- name: Manager-Specific Node Configuration
  hosts:
    - k3s_managers
  roles:
  tasks:

    - name: Install helm if not exists
      unarchive:
        src: https://get.helm.sh/helm-v3.15.3-linux-amd64.tar.gz
        dest: /usr/local/bin
        extra_opts: "--strip-components=1"
        owner: root
        group: root
        mode: 0755
        remote_src: true
      args:
        creates: /usr/local/bin/helm    


- name: Worker-Specific Node Configuration
  hosts:
    - k3s_workers
  roles:
    - nfs_base_role
    - nfs_music_role
    - nfs_video_role
    - nfs_temp_role
    - nfs_docs_role
    - nfs_pics_role
  tasks:

    # needed for wireguard VPN function of hotio's rflood
    - name: set the IPv4 sysctl parameter (net.ipv4.conf.all.src_valid_mark=1)
      ansible.posix.sysctl:
        name: net.ipv4.conf.all.src_valid_mark
        value:  '1'
        reload: true
        sysctl_set: true

    # optional for wireguard VPN function of hotio's rflood
    - name: set the IPv6 sysctl parameter (net.ipv6.conf.all.disable_ipv6=1)
      ansible.posix.sysctl:
        name: net.ipv6.conf.all.disable_ipv6
        value:  '1'
        reload: true
        sysctl_set: true

- name: Worker-Specific Node Configuration
  hosts:
    - k3s_GPU
  tasks:

    # Install NVIDIA Container Toolkit
    # save gpg key locally
    - name: get google key, save in /usr/share/keyrings for newer apt deb syntax
      get_url:
        url: https://nvidia.github.io/libnvidia-container/gpgkey
        dest: /usr/share/keyrings/nvidia-container-toolkit-keyring.asc
        mode: ugo+rw

    # add custom apt repo with 'signed-by' referring to gpg key
    - name: add nvidia container toolkit apt repository
      apt_repository:
        repo: "deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://nvidia.github.io/libnvidia-container/stable/deb/$(ARCH) /"
        state: present
        filename: /etc/apt/sources.list.d/nvidia-container-toolkit.list
        update_cache: yes
        mode: 0644
        validate_certs: no

    - name: install the nvidia container toolkit
      apt:
        name: 
          - nvidia-container-toolkit

- name: Worker-Specific Node Configuration
  hosts:
    - k3s_data
  vars:
    disks:
      - device:     /dev/nvme0n1
        partition:  /dev/nvme0n1p1
        mount_dir:  /var/lib/longhorn
  tasks:

    # need to format the drive
    - name: check the partitions
      community.general.parted:
        device: "{{ item.device }}"
        unit: MiB
      loop: "{{ disks|flatten(levels=1) }}"

    - name: create partition
      community.general.parted:
        device: "{{ item.device }}"
        number: 1
        label:  gpt
        state:  present
      loop: "{{ disks|flatten(levels=1) }}"

    - name: create filesystem
      community.general.filesystem:
        fstype: ext4
        state:  present
        device: "{{ item.partition }}"
      loop: "{{ disks|flatten(levels=1) }}"

    - name: create the device mount directory
      file:
        path: "{{ item.mount_dir }}"
        state:  directory
        recurse:  yes
      loop: "{{ disks|flatten(levels=1) }}"

    - name: mount the drive
      mount:
        src:  "{{ item.partition }}"
        path: "{{ item.mount_dir }}"
        fstype: ext4
        state:  mounted
      loop: "{{ disks|flatten(levels=1) }}"

    # packages and services for longhorn
    - name: install longhorn prerequisites
      apt:
        name:
          - open-iscsi
          - nfs-common
        state:  latest

    - name: start and enable services
      systemd:
        name:   "{{ item }}.service"
        state:  started
        enabled:  yes
      loop:
        - open-iscsi

        